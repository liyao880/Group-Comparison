else {
K[i]=0
}
}
i=1
if (p_public_train_K$V1[i]==i){
K[i]=p_public_train_K$V2[i]
}
K
K=rep(0,n)
View(p_public_train_K)
k=p_public_train_K
pubk=k
remove(p_public_train_K,k)
pubk[1,]
pubk[2,]
pubk[1:2,]
pubk[end,]
pubk[-1,]
i=3
tmp1=pubk[1:i,]
tmp2=pubk[(i+1):length(pubk),]
dim(pubk)[1]
tmp2=pubk[(i+1):dim(pubk)[1],]
pubk=rbind(tmp1,c(i,0),tmp2)
View(pubk)
pubk <- read.table("~/GitHub/Group-Comparison/data/pubjulia/p_public_train_K.txt", quote="\"")
View(pubk)
View(pubk)
pubk[7251,]
n=7266
for (i in 1:n){
if (pubk$V1[i]!=i){
tmp1=pubk[1:i,]
tmp2=pubk[(i+1):dim(pubk)[1],]
pubk=rbind(tmp1,c(i,0),tmp2)
}
}
View(pubk)
pubk <- read.table("~/GitHub/Group-Comparison/data/pubjulia/p_public_train_K.txt", quote="\"")
View(pubk)
i=1
if (pubk$V1[i]!=i){
tmp1=pubk[1:i,]
tmp2=pubk[i:dim(pubk)[1],]
pubk=rbind(tmp1,c(i,0),tmp2)
}
i=2
if (pubk$V1[i]!=i){
tmp1=pubk[1:i,]
tmp2=pubk[i:dim(pubk)[1],]
pubk=rbind(tmp1,c(i,0),tmp2)
}
n=7266
for (i in 1:n){
if (pubk$V1[i]!=i){
tmp1=pubk[1:i,]
tmp2=pubk[i:dim(pubk)[1],]
pubk=rbind(tmp1,c(i,0),tmp2)
}
}
View(tmp1)
dim(pubk)
View(pubk)
pubk
tmp1
pubk <- read.table("~/GitHub/Group-Comparison/data/pubjulia/p_public_train_K.txt", quote="\"")
View(pubk)
pubk$V1[2000]
pubk$V1[5000]
pubk$V1[4000]
pubk$V1[3000]
pubk$V1[2500]
pubk$V1[2700]
pubk$V1[2800]
pubk$V1[2750]
pubk$V1[2750:2800,]
pubk$V1[2750:2800]
i=2800
if (pubk$V1[i]!=i){
tmp1=pubk[1:i,]
tmp2=pubk[i:dim(pubk)[1],]
pubk=rbind(tmp1,c(i,0),tmp2)
}
pubk$V1[3000]
View(pubk)
pubk[3000,]
pubk[2790:2805,]
pubk <- read.table("~/GitHub/Group-Comparison/data/pubjulia/p_public_train_K.txt", quote="\"")
View(pubk)
i=288
i=2800
if (pubk$V1[i]!=i){
tmp1=pubk[1:(i-1),]
tmp2=pubk[i:dim(pubk)[1],]
pubk=rbind(tmp1,c(i,0),tmp2)
}
pubk[2790:2805,]
n=7266
for (i in 1:n){
if (pubk$V1[i]!=i){
tmp1=pubk[1:(i-1),]
tmp2=pubk[i:dim(pubk)[1],]
pubk=rbind(tmp1,c(i,0),tmp2)
}
}
pubk=rbind(tmp1,tmp2)
pubk$V1[7000,]
pubk$V1[7000]
pubk$V1[7200]
pubk$V1[7230]
pubk$V1[7230:7265]
pubk[7230:7265,]
i=7242
if (pubk$V1[i]!=i){
tmp1=pubk[1:(i-1),]
tmp2=pubk[i:dim(pubk)[1],]
pubk=rbind(tmp1,c(i,0),tmp2)
}
View(pubk)
pubk[7266,]
pubk[7240,]
pubk[3000,]
pubk <- read.table("~/GitHub/Group-Comparison/data/pubjulia/p_public_train_K.txt", quote="\"")
View(pubk)
n=7266
for (i in 1:n){
if (pubk$V1[i]!=i){
tmp1=pubk[1:(i-1),]
tmp2=pubk[i:dim(pubk)[1],]
pubk=rbind(tmp1,c(i,0),tmp2)
}
}
write.table(pubk,'BT_player_K.txt',col.names=F,row.names=F)
dota_player_W_train <- read.table("~/GitHub/Group-Comparison/data/dota/dota_player_W_train", quote="\"")
View(dota_player_W_train)
dota_player_W_test <- read.table("~/GitHub/Group-Comparison/data/dota/dota_player_W_test", quote="\"")
View(dota_player_W_test)
dota_player_L_train <- read.table("~/GitHub/Group-Comparison/data/dota/dota_player_L_train", quote="\"")
View(dota_player_L_train)
dota_player_L_test <- read.table("~/GitHub/Group-Comparison/data/dota/dota_player_L_test", quote="\"")
View(dota_player_L_test)
win_player=rbind(dota_player_W_train,dota_player_W_test)
lose_player=rbind(dota_player_L_train,dota_player_L_test)
dota_player_K=getK(win_player,lose_player)
getK=function(win_player,lose_player){
win=as.vector(as.matrix(win_player))
lose=as.vector(as.matrix(lose_player))
total=c(win,lose)
tb=table(total)
#K=as.vector(tb)
K=as.data.frame(tb)
return(K)
}
dota_player_K=getK(win_player,lose_player)
View(dota_player_K)
dota_player_train_K=getK(dota_player_W_train,dota_player_L_train)
n=33127
pubk=dota_player_train_K
for (i in 1:n){
if (pubk$V1[i]!=i){
tmp1=pubk[1:(i-1),]
tmp2=pubk[i:dim(pubk)[1],]
pubk=rbind(tmp1,c(i,0),tmp2)
}
}
View(pubk)
for (i in 1:n){
if (pubk$total[i]!=i){
tmp1=pubk[1:(i-1),]
tmp2=pubk[i:dim(pubk)[1],]
pubk=rbind(tmp1,c(i,0),tmp2)
}
}
write.table(pubk,'dota_player_K.txt',col.names=F,row.names=F)
dota_player_L_test <- read.table("~/GitHub/Group-Comparison/data/dota/dota_player_L_test", quote="\"")
View(dota_player_L_test)
write.table(dota_player_L_test,'dota_player_L_test.txt',col.names=F,row.names=F)
?write.csv2
write.csv2(dota_player_L_test,'dota_player_L_test.csv',col.names=F,row.names=F)
write.csv2(dota_player_L_test,'dota_player_L_test.csv')
heroranks.small=read.csv("~/Documents/ACADEMIC/Machine Learning/03HS/data/hotspairsrankings/heroranks-small.csv")
View(heroranks.small)
pair1=subset(heroranks.small,heroranks.small$tier==1)
pair9=subset(heroranks.small,heroranks.small$tier==9)
selectpairs=rbind(pair1,pair9)[,2:3]
load("~/GitHub/Group-Comparison/data/tournament/XY.RData")
rm(list=setdiff(ls(), "Cname"))
load("~/Documents/ACADEMIC/Machine Learning/03HS/data/data01_char/progress1.1.RData")
rm(list=setdiff(ls(), "Cname"))
heroranks.small=read.csv("~/Documents/ACADEMIC/Machine Learning/03HS/data/hotspairsrankings/heroranks-small.csv")
pair1=subset(heroranks.small,heroranks.small$tier==1)
pair9=subset(heroranks.small,heroranks.small$tier==9)
selectpairs=rbind(pair1,pair9)[,2:3]
remove(pair1,pair9)
View(heroranks.small)
remove(heroranks.small)
getselection=function(a){
ind=rep(0,2)
ind[1]=which(Cname==a[1,1])
ind[2]=which(Cname==a[1,2])
return(ind)
}
Selection=data.frame()
k=dim(selectpairs)[1]
for (i in 1:k){
Selection=rbind(Selection,getselection(selectpairs[i,]))
}
View(Selection)
Selection1=Selection
heroranks.small=read.csv("~/Documents/ACADEMIC/Machine Learning/03HS/data/hotspairsrankings/heroranks-small.csv")
pair1=subset(heroranks.small,heroranks.small$tier==1)
pair9=subset(heroranks.small,heroranks.small$tier==9)
pair2=subset(heroranks.small,heroranks.small$tier==2)
pair8=subset(heroranks.small,heroranks.small$tier==8)
selectpairs=rbind(pair1,pair2,pair8,pair9)[,2:3]
Selection=data.frame()
k=dim(selectpairs)[1]
for (i in 1:k){
Selection=rbind(Selection,getselection(selectpairs[i,]))
}
Selection2=Selection
View(Selection2)
View(Selection1)
pair3=subset(heroranks.small,heroranks.small$tier==3)
pair7=subset(heroranks.small,heroranks.small$tier==7)
selectpairs=rbind(pair1,pair2,pair3,pair7,pair8,pair9)[,2:3]
Selection=data.frame()
k=dim(selectpairs)[1]
for (i in 1:k){
Selection=rbind(Selection,getselection(selectpairs[i,]))
}
Selection3=Selection
pair4=subset(heroranks.small,heroranks.small$tier==4)
pair6=subset(heroranks.small,heroranks.small$tier==6)
selectpairs=rbind(pair1,pair2,pair3,pair4,pair6,pair7,pair8,pair9)[,2:3]
Selection=data.frame()
k=dim(selectpairs)[1]
for (i in 1:k){
Selection=rbind(Selection,getselection(selectpairs[i,]))
}
Selection4=Selection
selectpairs=heroranks.small[,2:3]
View(selectpairs)
Selection=data.frame()
k=dim(selectpairs)[1]
for (i in 1:k){
Selection=rbind(Selection,getselection(selectpairs[i,]))
}
View(Selection)
Selection5=Selection
remove(heroranks.small,pair1,pair2,pair3,pair4,pair6,pair7,pair8,pair9)
remove(Selection)
remove(selectpairs)
Selection=Selection1
chL_train <- read.table("~/GitHub/Group-Comparison/data/tournament/chL_train.txt", quote="\"")
View(chL_train)
chW_train <- read.table("~/GitHub/Group-Comparison/data/tournament/chW_train.txt", quote="\"")
View(chW_train)
chW_test <- read.table("~/GitHub/Group-Comparison/data/tournament/chW_test.txt", quote="\"")
View(chW_test)
chL_test <- read.table("~/GitHub/Group-Comparison/data/tournament/chL_test.txt", quote="\"")
View(chL_test)
n=dim(chL_train)[1]
k=dim(Selection)[1]
getpair=function(a){
b=data.frame(t(combn(a,2)))
ind=numeric()
for (i in 1:10){
tmp=which(Selection[,1]==b[i,1]&Selection[,2]==b[i,2])
ind=c(ind,tmp)
}
return(ind)
}
getpairind=function(a){
ind=getpair(a)
tmp=rep(0,k)
tmp[ind]=1
return(tmp)
}
X_sew=X_sel=data.frame()
for (i in 1:n){
X_sew=rbind(X_sew,getpairind(chW_train[i,]))
X_sel=rbind(X_sel,getpairind(chL_train[i,]))
}
save.image("~/Downloads/Select.RData")
X_se=X_sew-X_sel
X_se_train=cbind(X_LR_train,X_se)
load("~/GitHub/Group-Comparison/data/tournament/XY.RData")
X_se_train=cbind(X_LR_train,X_se)
X_se_train19=X_se_train
X_sew=X_sel=data.frame()
for (i in 1:(n/5)){
X_sew=rbind(X_sew,getpairind(chW_test[i,]))
X_sel=rbind(X_sel,getpairind(chL_test[i,]))
}
X_se=X_sew-X_sel
X_se_test=cbind(X_LR_test,X_se)
X_se_test=X_se_test19
X_se_test19=X_se_test
remove(X_sel,X_sew,X_test,X_train)
remove(X_se,X_se_test,X_se_train)
library(LiblineaR)
library(mclust)
accuracy1=1:10
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train,Y_train, type=0,cost=i,cross=5)
}
X_se_train=X_se_train19
X_se_test=X_se_test19
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train,Y_train, type=0,cost=i,cross=5)
}
fital1=LiblineaR(X_se_train,Y_train,type=0,cost=which.max(accuracy1))
fital1.pre=predict(fital1,X_se_test, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
Selection=Selection5
n=dim(chL_train)[1]
k=dim(Selection)[1]
X_sew=X_sel=data.frame()
for (i in 1:n){
X_sew=rbind(X_sew,getpairind(chW_train[i,]))
X_sel=rbind(X_sel,getpairind(chL_train[i,]))
}
load("~/Downloads/X_se_train4.RData")
load("~/Downloads/X_se_test4.RData")
X_se_train=X_se_train4
x_se_test=X_se_test4
accuracy1=1:10
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train,Y_train, type=0,cost=i,cross=5)
}
fital1=LiblineaR(X_se_train,Y_train,type=0,cost=which.max(accuracy1))
fital1.pre=predict(fital1,X_se_test, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
View(X_se_train4)
X_se_train1=X_se_train19
X_se_test1=X_se_test19
remove(X_se_test19,X_se_train19)
remove(x_se_test)
remove(X_se_test,X_se_train)
remove(X_sel,X_sew)
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train4,Y_train, type=0,cost=i,cross=5)
}
fital1=LiblineaR(X_se_train4,Y_train,type=0,cost=which.max(accuracy1))
fital1.pre=predict(fital1,X_se_test4, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
load("~/Downloads/X_se_train3.RData")
load("~/Downloads/X_se_test3.RData")
View(X_se_test4)
accuracy1=1:10
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train3,Y_train, type=0,cost=i,cross=5)
}
fital1=LiblineaR(X_se_train3,Y_train,type=0,cost=which.max(accuracy1))
fital1.pre=predict(fital1,X_se_test3, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
accuracy1=1:10
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train4,Y_train, type=0,cost=i,cross=5)
}
fital1=LiblineaR(X_se_train4,Y_train,type=0,cost=which.max(accuracy1))
fital1.pre=predict(fital1,X_se_test4, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
accuracy1=1:10
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train4,Y_train, type=0,cost=i,cross=5)
}
plot(accuracy1)
accuracy1=1:100
for (i in 1:100){
accuracy1[i]=LiblineaR(X_se_train4,Y_train, type=0,cost=i,cross=5)
}
fital1=LiblineaR(X_se_train4,Y_train,type=0,cost=which.max(accuracy1))
which.max(accuracy1)
fital1.pre=predict(fital1,X_se_test4, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
remove(Selection,Selection1,Selection2)
remove(Selection3,Selection4,Selection5)
remove(chL_test,chL_train,chW_test,chW_train)
remove(spl)
remove(X_LR_test,X_LR_train)
load("~/Downloads/X_se_test2.RData")
load("~/Downloads/X_se_train2.RData")
accuracy1=1:10
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train2,Y_train, type=0,cost=i,cross=5)
}
fital1=LiblineaR(X_se_train2,Y_train,type=0,cost=which.max(accuracy1))
fital1.pre=predict(fital1,X_se_test2, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
accuracy1=1:10
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train2,Y_train, type=0,cost=i,cross=5)
}
fital1=LiblineaR(X_se_train2,Y_train,type=0,cost=which.max(accuracy1))
## Predicting on the testing dataset
fital1.pre=predict(fital1,X_se_test2, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
load("~/Downloads/X_se_train5.RData")
heroranks.small=read.csv("~/Documents/ACADEMIC/Machine Learning/03HS/data/hotspairsrankings/heroranks-small.csv")
596-542
remove(heroranks.small)
load("~/Downloads/X_se_test5.RData")
accuracy1=1:10
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train5,Y_train, type=0,cost=i,cross=5)
}
View(X_se_train5)
save.image("~/GitHub/Group-Comparison/experiment result/LR_select/XY_select.RData")
fital1=LiblineaR(X_se_train5,Y_train,type=0,cost=which.max(accuracy1))
fital1.pre=predict(fital1,X_se_test5, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
accuracy1=1:10
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train5,Y_train, type=0,cost=i,cross=5)
}
fital1=LiblineaR(X_se_train5,Y_train,type=0,cost=which.max(accuracy1))
## Predicting on the testing dataset
fital1.pre=predict(fital1,X_se_test5, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
load("~/GitHub/Group-Comparison/experiment result/LR_select/XY_select.RData")
library(LiblineaR)
library(mclust)
accuracy1=1:100
for (i in 1:100){
accuracy1[i]=LiblineaR(X_se_train1,Y_train, type=0,cost=i,cross=5)
}
which.max(accuracy1)
fital1=LiblineaR(X_se_train1,Y_train,type=0,cost=which.max(accuracy1))
fital1.pre=predict(fital1,X_se_test1, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
fital1=LiblineaR(X_se_train1,Y_train,type=0,cost=which.max(accuracy1))
## Predicting on the testing dataset
fital1.pre=predict(fital1,X_se_test1, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
fital1=LiblineaR(X_se_train1,Y_train,type=0,cost=which.max(accuracy1))
## Predicting on the testing dataset
fital1.pre=predict(fital1,X_se_test1, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
fital1=LiblineaR(X_se_train1,Y_train,type=0,cost=which.max(accuracy1))
## Predicting on the testing dataset
fital1.pre=predict(fital1,X_se_test1, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
accuracy1=1:100
for (i in 1:100){
accuracy1[i]=LiblineaR(X_se_train2,Y_train, type=0,cost=i,cross=5)
}
fital1=LiblineaR(X_se_train2,Y_train,type=0,cost=which.max(accuracy1))
fital1.pre=predict(fital1,X_se_test2, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
fital1=LiblineaR(X_se_train2,Y_train,type=0,cost=which.max(accuracy1))
## Predicting on the testing dataset
fital1.pre=predict(fital1,X_se_test2, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
fital1=LiblineaR(X_se_train2,Y_train,type=0,cost=which.max(accuracy1))
## Predicting on the testing dataset
fital1.pre=predict(fital1,X_se_test2, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
which.max(accuracy1)
fital1=LiblineaR(X_se_train2,Y_train,type=0,cost=which.max(accuracy1[1:10]))
fital1.pre=predict(fital1,X_se_test2, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
accuracy1=1:10
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train3,Y_train, type=0,cost=i,cross=5)
}
fital1=LiblineaR(X_se_train3,Y_train,type=0,cost=which.max(accuracy1))
fital1.pre=predict(fital1,X_se_test3, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
accuracy1=1:10
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train4,Y_train, type=0,cost=i,cross=5)
}
fital1=LiblineaR(X_se_train4,Y_train,type=0,cost=which.max(accuracy1))
fital1.pre=predict(fital1,X_se_test4, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
accuracy1=1:10
for (i in 1:10){
accuracy1[i]=LiblineaR(X_se_train5,Y_train, type=0,cost=i,cross=5)
}
fital1=LiblineaR(X_se_train5,Y_train,type=0,cost=which.max(accuracy1))
## Predicting on the testing dataset
fital1.pre=predict(fital1,X_se_test5, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
fital1=LiblineaR(X_se_train5,Y_train,type=0,cost=which.max(accuracy1))
## Predicting on the testing dataset
fital1.pre=predict(fital1,X_se_test5, proba = FALSE,decisionValues = FALSE)$predictions
fital1.prerror=classError(fital1.pre,Y_test)
1-fital1.prerror$errorRate
